#!/usr/bin/env python

#
# genomicsdb_query python script
#
# The MIT License
#
# Copyright (c) 2024 dātma, inc™
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
#

import genomicsdb
from genomicsdb.protobuf import genomicsdb_export_config_pb2 as query_pb
from genomicsdb.protobuf import genomicsdb_coordinates_pb2 as query_coords

import argparse
import json
import pandas as pd
import re
import sys

interval_pattern = re.compile(r"(.*):(.*)-(.*)|(.*):(.*)|(.*)")
def parse_interval(interval:str):
  result = re.match(interval_pattern, interval)
  if result:
    length = len(result.groups())
    if length == 6:
      if result.group(1) and result.group(2) and result.group(3):
        return result.group(1), int(result.group(2)), int(result.group(3))
      elif result.group(4) and result.group(5):
        return result.group(4), int(result.group(5)), None 
      elif result.group(6):
        return result.group(6), 1, None
  raise RuntimeError(f"Interval {interval} could not be parsed")

def generate_output_filename(output, interval, idx):
  output_filename = f"{output}_{interval.replace(':', '-')}"
  if idx > 0:
    output_filename = output_filename + f"_{idx}"
  return output_filename + ".csv"

def main():
  parser = argparse.ArgumentParser(prog="query", description="GenomicsDB simple query", usage="%(prog)s [options]")
  parser.add_argument(
    "--version",
    action="store_true",
    help="print GenomicsDB native library version and exit")
  parser.add_argument(
    "-w",
    "--workspace",
    required=True,
    help="URL to GenomicsDB workspace, e.g. -w my_workspace or -w az://my_container/my_workspace" +
    " or -w s3://my_bucket/my_workspace or -w gs://my_bucket/my_workspace")
  parser.add_argument("-v", "--vidmap", required=False, help="Optional - URL to vid mapping file. Defaults to vidmap.json in workspace")
  parser.add_argument("-l", "--loader", required=False, help="Optional - URL to loader file. Defaults to loader.json in workspace") 
  parser.add_argument("-L","--interval",
                      action="append",
                      required=True,
                      help="One or more genomic intervals over which to operate. This argument may be specified 1 or more times e.g -L chr1:1-10000 -L chr2 -L chr3:1000")
  parser.add_argument("-f", "--filter", required=False, help="Optional - genomic filter expression for the query, e.g. 'ISHOMREF' or 'ISHET' or 'REF == \"G\" && resolve(GT, REF, ALT) &= \"T/T\" && ALT |= \"T\"'")
  parser.add_argument("-o", "--output", required=True, help="a prefix filename to csv outputs from the tool. The filenames will be suffixed with the interval and .csv")
  

  args = parser.parse_args()
  if args.version:
    print(f"GenomicsDB native library version={genomicsdb.version()}")
    sys.exit(0)
    
  workspace=args.workspace
  if not genomicsdb.is_file(workspace+"/__tiledb_workspace.tdb"):
    raise RuntimeError(f"workspace({workspace}) not found")
  vidmap_file = args.vidmap
  if not vidmap_file:
    vidmap_file = workspace+"/vidmap.json"
  loader_file = args.loader
  if not loader_file:
    loader_file = workspace+"/loader.json"
  if not genomicsdb.is_file(vidmap_file) or not genomicsdb.is_file(loader_file):
    raise RuntimeError(f"vidmap({vidmap_file}) or loader({loader_file}) not found")
  intervals=args.interval
  filter=args.filter
  output=args.output
  
  #parse vidmap.json
  contigs_map = {}
  vidmap = json.loads(genomicsdb.read_entire_file(vidmap_file))
  contigs = vidmap["contigs"]
  for contig in contigs:
    contigs_map[contig["name"]] = contig

  #parse loader.json
  loader = json.loads(genomicsdb.read_entire_file(loader_file))
  partitions = loader["column_partitions"]

  export_config = query_pb.ExportConfiguration()
  export_config.workspace = workspace
  export_config.attributes.extend(["REF", "ALT", "GT"])
  export_config.callset_mapping_file = workspace+"/callset.json"
  export_config.vid_mapping_file = workspace+"/vidmap.json"
  export_config.bypass_intersecting_intervals_phase = False
  export_config.enable_shared_posixfs_optimizations = True
  if filter:
    export_config.query_filter = filter
  gdb = genomicsdb.connect_with_protobuf(export_config)

  print(f"Starting genomicsdb_query for workspace({workspace}) and intervals({intervals})")
  for interval in intervals:
    print(f"Processing interval({interval})...")
    # query column interval
    # get tiledb offsets for interval
    contig, start, end = parse_interval(interval)
    if contig in contigs_map:
      contig_offset = start+contigs_map[contig]["tiledb_column_offset"]-1
      length = contigs_map[contig]["length"]
      if end and end<length+1:
        contig_end = contig_offset + end - start
      else:
        end = length
        contig_end = length - 1
    else:
      raise RuntimeError(f"Contig({contig} not found in vidmap.json")

    arrays=[]
    for partition in partitions:
      if contig_end < partition["begin"]["tiledb_column"] or contig_offset > partition["end"]["tiledb_column"]:
          continue
      if partition["workspace"] != workspace:
          raise RuntimeError(f"Partiton workspaces({partition['workspace']} different from input workspace{workspace} not supported")
      arrays.append(partition["array_name"])
    print(f"Arrays:{arrays} under consideration for interval({interval})")
    arrays_length = len(arrays)
    if arrays_length == 0:
      print(f"No arrays in the workspace matched input interval({interval})")
      continue

    for idx, array in enumerate(arrays):
      query_config = query_pb.QueryConfiguration()
      query_config.array_name=array
      # query column interval
      contig_interval = query_coords.ContigInterval()
      contig_interval.contig = contig
      contig_interval.begin = start
      contig_interval.end = end
      query_config.query_contig_intervals.extend([contig_interval])
      df = gdb.query_variant_calls(query_protobuf=query_config, flatten_intervals=True)
      df.to_csv(generate_output_filename(output, interval, idx), index=False)
  
  print(f"Starting genomicsdb_query for workspace({workspace}) and intervals({intervals}) DONE")

if __name__ == "__main__":
    main()
  
